# LLM_CMP

-  Switch to your LLM: Change corresponding code in eval.py to prepare your tokenizer, model and generation_config
- To implement it on a cluster, you need to implement LLM.sh and modify it based on your condition
- All data has been well prepared in this repo, just clone this repo
- Now only support ImpressionGPT, the results from LLM will be recorded in the ''pseudo_impression'' column of the csv file